using UnityEngine;
using UnityEngine.XR.OpenXR;
using VIVE.OpenXR.FacialTracking;
using VIVE.OpenXR.Samples.FacialTracking;
using System.Collections;
using UnityEngine.XR.Management;
using System.Linq;

/// <summary>
/// VIVE Facial Tracker ì „ìš© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
/// VIVE Pro 2 + VIVE Facial Tracker ì¡°í•©ì— ìµœì í™”
/// </summary>
public class VIVEFacialTrackerTest : MonoBehaviour
{
    [Header("Status")]
    public string currentStatus = "Not Started";
    public bool isSessionCreated = false;
    public bool isEyeTrackingSupported = false;
    public bool isLipTrackingSupported = false;
    
    [Header("Debug Options")]
    public bool verboseLogging = true;
    public bool autoRetry = true;
    public int maxRetryAttempts = 3;
    
    private ViveFacialTracking facialTrackingFeature;
    private float[] eyeBlendShapes;
    private float[] lipBlendShapes;
    private int retryCount = 0;
    
    void Start()
    {
        StartCoroutine(InitializationSequence());
    }
    
    IEnumerator InitializationSequence()
    {
        LogInfo("ğŸš€ Starting VIVE Facial Tracker initialization...");
        currentStatus = "Initializing...";
        
        // 1. ê¸°ë³¸ ì‹œìŠ¤í…œ ì²´í¬
        yield return CheckBasicRequirements();
        
        // 2. OpenXR ì´ˆê¸°í™” ëŒ€ê¸°
        yield return WaitForOpenXRInitialization();
        
        // 3. ì„¸ì…˜ ìƒì„± ëŒ€ê¸°
        yield return WaitForSessionCreation();
        
        // 4. Facial Tracking ì´ˆê¸°í™”
        yield return InitializeFacialTracking();
    }
    
    IEnumerator CheckBasicRequirements()
    {
        currentStatus = "Checking requirements...";
        
        // OpenXR ë¡œë” í™•ì¸
        if (XRGeneralSettings.Instance == null || 
            XRGeneralSettings.Instance.Manager == null ||
            XRGeneralSettings.Instance.Manager.activeLoader == null)
        {
            LogError("âŒ XR Loader not active! Check XR Plug-in Management settings.");
            yield break;
        }
        
        // Mock Runtime ì²´í¬
        var mockRuntime = OpenXRSettings.Instance?.GetFeature<VIVE.OpenXR.Feature.ViveMockRuntime>();
        if (mockRuntime != null && mockRuntime.enabled)
        {
            LogWarning("âš ï¸ Mock Runtime is enabled! Disable it for real device testing.");
            LogInfo("Project Settings > XR Plug-in Management > OpenXR > VIVE OpenXR > Mock Runtime");
        }
        
        yield return null;
    }
    
    IEnumerator WaitForOpenXRInitialization()
    {
        currentStatus = "Waiting for OpenXR...";
        float timeout = 10f;
        float elapsed = 0f;
        
        while (OpenXRSettings.Instance == null)
        {
            if (elapsed > timeout)
            {
                LogError("âŒ OpenXR initialization timeout!");
                yield break;
            }
            
            elapsed += 0.5f;
            yield return new WaitForSeconds(0.5f);
        }
        
        LogInfo("âœ… OpenXR initialized");
        
        // Feature ëª©ë¡ ì¶œë ¥
        if (verboseLogging)
        {
            LogInfo("Checking enabled OpenXR features...");
            
            // ViveFacialTracking feature í™•ì¸
            var facialFeature = OpenXRSettings.Instance.GetFeature<ViveFacialTracking>();
            if (facialFeature != null && facialFeature.enabled)
            {
                LogInfo("âœ… ViveFacialTracking feature is enabled!");
            }
            else
            {
                LogWarning("âš ï¸ ViveFacialTracking feature not found or disabled");
            }
            
            // ë‹¤ë¥¸ VIVE ê¸°ëŠ¥ë“¤ í™•ì¸
            var mockRuntime = OpenXRSettings.Instance.GetFeature<VIVE.OpenXR.Feature.ViveMockRuntime>();
            if (mockRuntime != null && mockRuntime.enabled)
            {
                LogWarning("âš ï¸ Mock Runtime is still enabled!");
            }
        }
    }
    
    IEnumerator WaitForSessionCreation()
    {
        currentStatus = "Waiting for XR Session...";
        
        // OpenXRì˜ ì„¸ì…˜ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ë” ë‚˜ì€ ë°©ë²•
        // XR ë””ë°”ì´ìŠ¤ê°€ ì—°ê²°ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        float timeout = 15f;
        float elapsed = 0f;
        
        while (!IsXRDevicePresent())
        {
            if (elapsed > timeout)
            {
                LogError("âŒ XR Device connection timeout!");
                yield break;
            }
            
            LogInfo($"Waiting for XR device... ({elapsed:F1}s)");
            elapsed += 1f;
            yield return new WaitForSeconds(1f);
        }
        
        // ì¶”ê°€ ì•ˆì •í™” ì‹œê°„
        LogInfo("XR Device detected, stabilizing...");
        yield return new WaitForSeconds(3f);
        
        isSessionCreated = true;
        LogInfo("âœ… XR Session ready");
    }
    
    bool IsXRDevicePresent()
    {
        var devices = new System.Collections.Generic.List<UnityEngine.XR.InputDevice>();
        UnityEngine.XR.InputDevices.GetDevicesWithCharacteristics(
            UnityEngine.XR.InputDeviceCharacteristics.HeadMounted, devices);
        return devices.Count > 0;
    }
    
    IEnumerator InitializeFacialTracking()
    {
        currentStatus = "Initializing Facial Tracking...";
        
        // Feature ê°€ì ¸ì˜¤ê¸°
        facialTrackingFeature = OpenXRSettings.Instance?.GetFeature<ViveFacialTracking>();
        
        if (facialTrackingFeature == null)
        {
            LogError("âŒ ViveFacialTracking feature not found!");
            LogInfo("Check: Project Settings > XR Plug-in Management > OpenXR > VIVE OpenXR > Facial Tracking");
            yield break;
        }
        
        if (!facialTrackingFeature.enabled)
        {
            LogError("âŒ ViveFacialTracking feature is not enabled!");
            yield break;
        }
        
        LogInfo("âœ… ViveFacialTracking feature found and enabled");
        
        // ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ íŠ¸ë˜ì»¤ ìƒì„±
        bool eyeCreated = false;
        bool lipCreated = false;
        
        for (int i = 0; i < maxRetryAttempts; i++)
        {
            if (!eyeCreated)
            {
                LogInfo($"Attempting to create Eye tracker... (attempt {i + 1}/{maxRetryAttempts})");
                eyeCreated = TryCreateTracker(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC, "Eye");
            }
            
            if (!lipCreated)
            {
                LogInfo($"Attempting to create Lip tracker... (attempt {i + 1}/{maxRetryAttempts})");
                lipCreated = TryCreateTracker(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC, "Lip");
            }
            
            if (eyeCreated && lipCreated) break;
            
            if (i < maxRetryAttempts - 1)
            {
                LogInfo("Retrying in 2 seconds...");
                yield return new WaitForSeconds(2f);
            }
        }
        
        isEyeTrackingSupported = eyeCreated;
        isLipTrackingSupported = lipCreated;
        
        if (eyeCreated || lipCreated)
        {
            currentStatus = "Facial Tracking Ready";
            LogInfo("ğŸ‰ Facial tracking initialized successfully!");
            LogInfo($"   Eye Tracking: {(eyeCreated ? "âœ…" : "âŒ")}");
            LogInfo($"   Lip Tracking: {(lipCreated ? "âœ…" : "âŒ")}");
            
            // ë°ì´í„° ì½ê¸° ì‹œì‘
            StartCoroutine(ReadFacialData());
        }
        else
        {
            currentStatus = "Facial Tracking Failed";
            LogError("âŒ Failed to initialize any facial tracking!");
            LogInfo("Possible reasons:");
            LogInfo("1. VIVE Facial Tracker not connected properly");
            LogInfo("2. Driver not installed");
            LogInfo("3. SteamVR not recognizing the tracker");
            LogInfo("4. OpenXR runtime not supporting the extension");
        }
    }
    
    bool TryCreateTracker(XrFacialTrackingTypeHTC trackingType, string typeName)
    {
        try
        {
            bool created = facialTrackingFeature.CreateFacialTracker(trackingType);
            if (created)
            {
                LogInfo($"âœ… {typeName} tracker created successfully!");
                return true;
            }
            else
            {
                LogWarning($"âŒ Failed to create {typeName} tracker");
                return false;
            }
        }
        catch (System.Exception e)
        {
            LogError($"Exception creating {typeName} tracker: {e.Message}");
            return false;
        }
    }
    
    IEnumerator ReadFacialData()
    {
        while (isEyeTrackingSupported || isLipTrackingSupported)
        {
            // Eye data
            if (isEyeTrackingSupported)
            {
                if (facialTrackingFeature.GetFacialExpressions(
                    XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC, 
                    out eyeBlendShapes))
                {
                    ProcessEyeData(eyeBlendShapes);
                }
            }
            
            // Lip data
            if (isLipTrackingSupported)
            {
                if (facialTrackingFeature.GetFacialExpressions(
                    XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC, 
                    out lipBlendShapes))
                {
                    ProcessLipData(lipBlendShapes);
                }
            }
            
            yield return new WaitForSeconds(0.1f); // 10Hz update
        }
    }
    
    void ProcessEyeData(float[] shapes)
    {
        if (shapes == null || shapes.Length == 0) return;
        
        float leftBlink = shapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_LEFT_BLINK_HTC];
        float rightBlink = shapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_RIGHT_BLINK_HTC];
        
        if (leftBlink > 0.1f || rightBlink > 0.1f)
        {
            LogInfo($"ğŸ‘ï¸ Eye: Blink L:{leftBlink:F2} R:{rightBlink:F2}");
        }
    }
    
    void ProcessLipData(float[] shapes)
    {
        if (shapes == null || shapes.Length == 0) return;
        
        float jawOpen = shapes[(int)XrLipShapeHTC.XR_LIP_SHAPE_JAW_OPEN_HTC];
        
        if (jawOpen > 0.1f)
        {
            LogInfo($"ğŸ‘„ Lip: Jaw Open {jawOpen:F2}");
        }
    }
    
    void LogInfo(string message)
    {
        Debug.Log($"[VIVEFacialTracker] {message}");
    }
    
    void LogWarning(string message)
    {
        Debug.LogWarning($"[VIVEFacialTracker] {message}");
    }
    
    void LogError(string message)
    {
        Debug.LogError($"[VIVEFacialTracker] {message}");
    }
    
    void OnDestroy()
    {
        if (facialTrackingFeature != null)
        {
            if (isEyeTrackingSupported)
            {
                facialTrackingFeature.DestroyFacialTracker(
                    XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC);
            }
            
            if (isLipTrackingSupported)
            {
                facialTrackingFeature.DestroyFacialTracker(
                    XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC);
            }
        }
    }
} 