using UnityEngine;
using UnityEngine.XR.OpenXR;
using VIVE.OpenXR.FacialTracking;
using VIVE.OpenXR.Samples.FacialTracking;
using System.Linq;

public class DetailedFacialTrackingTest : MonoBehaviour
{
    private ViveFacialTracking facialTrackingFeature;
    private float[] eyeBlendShapes;
    private float[] lipBlendShapes;
    
    [Header("Debug Settings")]
    public bool showAllValues = false;  // ëª¨ë“  ê°’ í‘œì‹œ
    public float threshold = 0.1f;      // ì´ ê°’ ì´ìƒë§Œ í‘œì‹œ
    
    void Start()
    {
        facialTrackingFeature = OpenXRSettings.Instance.GetFeature<ViveFacialTracking>();
        
        if (facialTrackingFeature == null)
        {
            Debug.LogError("ViveFacialTracking feature is not enabled! Please enable it in OpenXR Settings.");
            return;
        }
        
        Debug.Log("âœ… ViveFacialTracking feature is enabled and ready!");
    }
    
    void Update()
    {
        if (facialTrackingFeature == null) return;
        
        // Eye Tracking í…ŒìŠ¤íŠ¸
        TestEyeTracking();
        
        // Lip Tracking í…ŒìŠ¤íŠ¸
        TestLipTracking();
    }
    
    void TestEyeTracking()
    {
        if (!facialTrackingFeature.GetFacialExpressions(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC, out eyeBlendShapes))
            return;
        
        // ì£¼ìš” ëˆˆ í‘œì •ë§Œ ì²´í¬
        LogIfActive("ğŸ‘ï¸ Left Blink", eyeBlendShapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_LEFT_BLINK_HTC]);
        LogIfActive("ğŸ‘ï¸ Right Blink", eyeBlendShapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_RIGHT_BLINK_HTC]);
        LogIfActive("ğŸ‘ï¸ Left Wide", eyeBlendShapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_LEFT_WIDE_HTC]);
        LogIfActive("ğŸ‘ï¸ Right Wide", eyeBlendShapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_RIGHT_WIDE_HTC]);
        
        if (showAllValues)
        {
            Debug.Log($"[Eye Tracking] Active values: {CountActiveValues(eyeBlendShapes)}");
        }
    }
    
    void TestLipTracking()
    {
        if (!facialTrackingFeature.GetFacialExpressions(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC, out lipBlendShapes))
            return;
        
        // ì£¼ìš” ì… í‘œì •ë§Œ ì²´í¬
        LogIfActive("ğŸ‘„ Jaw Open", lipBlendShapes[(int)XrLipShapeHTC.XR_LIP_SHAPE_JAW_OPEN_HTC]);
        LogIfActive("ğŸ‘„ Mouth Raiser Right", lipBlendShapes[(int)XrLipShapeHTC.XR_LIP_SHAPE_MOUTH_RAISER_RIGHT_HTC]);
        LogIfActive("ğŸ‘„ Mouth Raiser Left", lipBlendShapes[(int)XrLipShapeHTC.XR_LIP_SHAPE_MOUTH_RAISER_LEFT_HTC]);
        LogIfActive("ğŸ‘„ Mouth Pout", lipBlendShapes[(int)XrLipShapeHTC.XR_LIP_SHAPE_MOUTH_POUT_HTC]);
        
        if (showAllValues)
        {
            Debug.Log($"[Lip Tracking] Active values: {CountActiveValues(lipBlendShapes)}");
        }
    }
    
    void LogIfActive(string name, float value)
    {
        if (value > threshold)
        {
            Debug.Log($"{name}: {value:F3}");
        }
    }
    
    int CountActiveValues(float[] values)
    {
        return values.Count(v => v > threshold);
    }
} 