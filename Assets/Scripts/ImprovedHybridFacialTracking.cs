using UnityEngine;
using UnityEngine.XR.OpenXR;
using VIVE.OpenXR.FacialTracking;
using VIVE.OpenXR.Samples.FacialTracking;
using System.Collections;
using UnityEngine.XR.Management;

/// <summary>
/// ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ì–¼êµ´ íŠ¸ë˜í‚¹ - XR ì„¸ì…˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì´ˆê¸°í™”
/// </summary>
public class ImprovedHybridFacialTracking : MonoBehaviour
{
    [Header("Mode")]
    public bool useMockData = false;
    public bool autoDetectMockRuntime = true;
    
    [Header("Initialization")]
    public float maxWaitTime = 10f; // ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
    
    [Header("Status")]
    public bool isXRSessionReady = false;
    public bool isFacialTrackingReady = false;
    public string currentStatus = "Not Started";
    
    [Header("Mock Controls")]
    private MockFacialTrackingTest mockController;
    
    [Header("Real Device")]
    private ViveFacialTracking facialTrackingFeature;
    private float[] eyeBlendShapes;
    private float[] lipBlendShapes;
    private bool isInitialized = false;
    
    void Start()
    {
        currentStatus = "Starting...";
        StartCoroutine(InitializeSequence());
    }
    
    IEnumerator InitializeSequence()
    {
        // 1. Mock Runtime ì²´í¬
        currentStatus = "Checking Mock Runtime...";
        yield return null;
        
        var mockRuntimeFeature = OpenXRSettings.Instance?.GetFeature<VIVE.OpenXR.Feature.ViveMockRuntime>();
        if (mockRuntimeFeature != null && mockRuntimeFeature.enabled)
        {
            Debug.LogWarning("ğŸ® Mock Runtime detected - switching to keyboard simulation");
            useMockData = true;
            InitializeMockMode();
            yield break;
        }
        
        // 2. XR System ì´ˆê¸°í™” ëŒ€ê¸°
        currentStatus = "Waiting for XR System...";
        float waitStartTime = Time.time;
        
        while (!XRGeneralSettings.Instance || 
               XRGeneralSettings.Instance.Manager == null || 
               !XRGeneralSettings.Instance.Manager.isInitializationComplete)
        {
            if (Time.time - waitStartTime > maxWaitTime)
            {
                Debug.LogError("âŒ XR System initialization timeout - switching to mock mode");
                useMockData = true;
                InitializeMockMode();
                yield break;
            }
            
            yield return new WaitForSeconds(0.5f);
        }
        
        Debug.Log("âœ… XR System initialized");
        
        // 3. OpenXR Session ëŒ€ê¸°
        currentStatus = "Waiting for OpenXR Session...";
        while (OpenXRSettings.Instance == null)
        {
            if (Time.time - waitStartTime > maxWaitTime)
            {
                Debug.LogError("âŒ OpenXR Session timeout - switching to mock mode");
                useMockData = true;
                InitializeMockMode();
                yield break;
            }
            
            yield return new WaitForSeconds(0.5f);
        }
        
        Debug.Log("âœ… OpenXR Session ready");
        isXRSessionReady = true;
        
        // 4. ì¶”ê°€ ì•ˆì •í™” ëŒ€ê¸°
        currentStatus = "Stabilizing...";
        yield return new WaitForSeconds(2f);
        
        // 5. ì–¼êµ´ íŠ¸ë˜í‚¹ ì´ˆê¸°í™”
        currentStatus = "Initializing Facial Tracking...";
        InitializeRealDevice();
    }
    
    void InitializeMockMode()
    {
        currentStatus = "Mock Mode Active";
        
        if (mockController == null)
        {
            mockController = gameObject.AddComponent<MockFacialTrackingTest>();
        }
        
        Debug.Log("ğŸ® Mock Mode Active - Keyboard Controls:");
        Debug.Log("   Q/W: Eye Blink | A/S: Eye Wide");
        Debug.Log("   Z: Jaw Open | X: Pout | C/V: Smile");
        Debug.Log("   Space: Reset | Enter: Auto Animation");
        
        isInitialized = true;
    }
    
    void InitializeRealDevice()
    {
        try
        {
            facialTrackingFeature = OpenXRSettings.Instance?.GetFeature<ViveFacialTracking>();
            
            if (facialTrackingFeature == null || !facialTrackingFeature.enabled)
            {
                Debug.LogError("âŒ ViveFacialTracking feature not available/enabled");
                currentStatus = "Feature Not Available - Using Mock";
                useMockData = true;
                InitializeMockMode();
                return;
            }
            
            // ê¸°ëŠ¥ ì§€ì› ì²´í¬
            bool eyeSupported = CheckAndCreateTracker(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC, "Eye");
            bool lipSupported = CheckAndCreateTracker(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC, "Lip");
            
            if (!eyeSupported && !lipSupported)
            {
                Debug.LogWarning("âš ï¸ No facial tracking support detected");
                currentStatus = "No Tracking Support - Using Mock";
                useMockData = true;
                InitializeMockMode();
                return;
            }
            
            currentStatus = "Real Device Ready";
            isFacialTrackingReady = true;
            isInitialized = true;
            
            Debug.Log("âœ… Real device facial tracking initialized!");
            Debug.Log($"   Eye Tracking: {(eyeSupported ? "âœ…" : "âŒ")}");
            Debug.Log($"   Lip Tracking: {(lipSupported ? "âœ…" : "âŒ")}");
        }
        catch (System.Exception e)
        {
            Debug.LogError($"âŒ Exception during initialization: {e.Message}");
            currentStatus = "Initialization Failed - Using Mock";
            useMockData = true;
            InitializeMockMode();
        }
    }
    
    bool CheckAndCreateTracker(XrFacialTrackingTypeHTC trackingType, string typeName)
    {
        try
        {
            // ë¨¼ì € ì§€ì› ì—¬ë¶€ ì²´í¬ (ì„¸ì…˜ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸)
            if (!isXRSessionReady)
            {
                Debug.LogWarning($"XR Session not ready for {typeName} tracking check");
                return false;
            }
            
            // íŠ¸ë˜ì»¤ ìƒì„± ì‹œë„
            bool created = facialTrackingFeature.CreateFacialTracker(trackingType);
            if (created)
            {
                Debug.Log($"âœ… {typeName} tracker created successfully");
                return true;
            }
            else
            {
                Debug.LogWarning($"âŒ Failed to create {typeName} tracker");
                return false;
            }
        }
        catch (System.Exception e)
        {
            Debug.LogError($"Exception checking {typeName} tracker: {e.Message}");
            return false;
        }
    }
    
    // Updateì™€ ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼...
    void Update()
    {
        if (!isInitialized) return;
        
        if (useMockData && mockController != null)
        {
            // Mock ë°ì´í„°ëŠ” MockFacialTrackingTestê°€ ìì²´ì ìœ¼ë¡œ ë¡œê·¸ ì¶œë ¥
        }
        else if (facialTrackingFeature != null)
        {
            ProcessRealData();
        }
    }
    
    void ProcessRealData()
    {
        // Eye Tracking
        if (facialTrackingFeature.GetFacialExpressions(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC, out eyeBlendShapes))
        {
            DetectEyeExpressions(eyeBlendShapes);
        }
        
        // Lip Tracking
        if (facialTrackingFeature.GetFacialExpressions(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC, out lipBlendShapes))
        {
            DetectLipExpressions(lipBlendShapes);
        }
    }
    
    void DetectEyeExpressions(float[] shapes)
    {
        if (shapes == null || shapes.Length == 0) return;
        
        float leftBlink = shapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_LEFT_BLINK_HTC];
        float rightBlink = shapes[(int)XrEyeShapeHTC.XR_EYE_EXPRESSION_RIGHT_BLINK_HTC];
        
        if (leftBlink > 0.1f || rightBlink > 0.1f)
            Debug.Log($"ğŸ‘ï¸ Blink - L: {leftBlink:F2}, R: {rightBlink:F2}");
    }
    
    void DetectLipExpressions(float[] shapes)
    {
        if (shapes == null || shapes.Length == 0) return;
        
        float jawOpen = shapes[(int)XrLipShapeHTC.XR_LIP_SHAPE_JAW_OPEN_HTC];
        
        if (jawOpen > 0.1f)
            Debug.Log($"ğŸ‘„ Jaw Open: {jawOpen:F2}");
    }
    
    void OnDestroy()
    {
        if (!useMockData && facialTrackingFeature != null && isInitialized)
        {
            try
            {
                facialTrackingFeature.DestroyFacialTracker(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_EYE_DEFAULT_HTC);
                facialTrackingFeature.DestroyFacialTracker(XrFacialTrackingTypeHTC.XR_FACIAL_TRACKING_TYPE_LIP_DEFAULT_HTC);
            }
            catch { }
        }
    }
} 